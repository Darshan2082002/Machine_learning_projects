{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fd4e6f2",
   "metadata": {},
   "source": [
    "# Skin Cancer Detection — **Demo** (HAM10000, ~100 images)\n",
    "\n",
    "**Colab-ready notebook (TensorFlow / Keras).**\n",
    "\n",
    "**What this demo does:**\n",
    "\n",
    "- Downloads a small subset (~100 images) of the HAM10000 dataset directly from Kaggle (you'll upload `kaggle.json` once in Colab).\n",
    "- Preprocesses images (resize 224×224, normalization, Gaussian denoising and simple hair removal).\n",
    "- Uses DenseNet201 (pretrained) + small Dense head for classification into lesion types.\n",
    "- Trains on 80% of the sampled images and evaluates on 20%.\n",
    "- Produces a performance table, confusion matrix, ROC curves and example predictions.\n",
    "\n",
    "**Instructions:** Run each cell in order. When prompted, upload your `kaggle.json` (Kaggle API token) so the notebook can download the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78fac98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installed packages (or verified existing installations).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'pip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# Install required packages (run in Colab)\n",
    "!pip install -q kaggle tensorflow matplotlib scikit-learn opencv-python-headless seaborn tqdm\n",
    "print('Installed packages (or verified existing installations).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb6969d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Upload kaggle.json in Colab when prompted (skip if running locally and dataset is already available)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m files\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mUpload kaggle.json now (Kaggle API token). If you already uploaded, cancel this upload dialog.\u001b[39m\u001b[33m'\u001b[39m) \n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "# Upload kaggle.json in Colab when prompted (skip if running locally and dataset is already available)\n",
    "from google.colab import files\n",
    "print('Upload kaggle.json now (Kaggle API token). If you already uploaded, cancel this upload dialog.') \n",
    "try:\n",
    "    uploaded = files.upload()\n",
    "    for fn in uploaded.keys():\n",
    "        print('Uploaded file:', fn)\n",
    "except Exception as e:\n",
    "    print('Upload canceled or not running in Colab:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85aa34a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move kaggle.json to ~/.kaggle and set permissions (Colab)\n",
    "import os, shutil\n",
    "if os.path.exists('kaggle.json'):\n",
    "    os.makedirs(os.path.expanduser('~/.kaggle'), exist_ok=True)\n",
    "    shutil.move('kaggle.json', os.path.expanduser('~/.kaggle/kaggle.json'))\n",
    "    os.chmod(os.path.expanduser('~/.kaggle/kaggle.json'), 0o600)\n",
    "    print('kaggle.json moved to ~/.kaggle/kaggle.json')\n",
    "else:\n",
    "    print('kaggle.json not found in current working directory. If you are running locally, ensure dataset files are present.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f99c517d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dataset from Kaggle (requires kaggle.json). This may take a few minutes depending on network speed.\n",
      "Dataset downloaded and unzipped. Files:\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'kaggle' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# Download HAM10000 dataset from Kaggle and unzip to /content/HAM10000\n",
    "import os\n",
    "os.makedirs('/content/HAM10000', exist_ok=True)\n",
    "print('Downloading dataset from Kaggle (requires kaggle.json). This may take a few minutes depending on network speed.')\n",
    "!kaggle datasets download -d kmader/skin-cancer-mnist-ham10000 -p /content/HAM10000 --unzip -q\n",
    "print('Dataset downloaded and unzipped. Files:')\n",
    "print(sorted(os.listdir('/content/HAM10000'))[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69dd730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata and sample ~100 images with class balancing\n",
    "import pandas as pd, glob, os, shutil\n",
    "meta_path = '/content/HAM10000/HAM10000_metadata.csv'\n",
    "assert os.path.exists(meta_path), \"Metadata CSV not found. Ensure download completed.\"\n",
    "meta = pd.read_csv(meta_path)\n",
    "print('Total metadata rows:', len(meta))\n",
    "print(meta['dx'].value_counts())\n",
    "\n",
    "# Map image ids to paths\n",
    "all_images = glob.glob('/content/HAM10000/*.jpg')\n",
    "id_to_path = { os.path.splitext(os.path.basename(p))[0]: p for p in all_images }\n",
    "meta['path'] = meta['image_id'].astype(str).map(id_to_path)\n",
    "meta = meta.dropna(subset=['path']).reset_index(drop=True)\n",
    "print('Rows with actual image files:', len(meta))\n",
    "\n",
    "# Sample up to 15 per class to get approx 100 images\n",
    "sampled = []\n",
    "max_per_class = 15\n",
    "for cls, g in meta.groupby('dx'):\n",
    "    sampled += g.sample(n=min(len(g), max_per_class), random_state=42)['path'].tolist()\n",
    "# make sure ~100 total\n",
    "sampled = sampled[:100]\n",
    "sample_dir = '/content/sample_images'\n",
    "os.makedirs(sample_dir, exist_ok=True)\n",
    "for p in sampled:\n",
    "    shutil.copy(p, sample_dir)\n",
    "print('Sampled images copied to', sample_dir, 'count =', len(os.listdir(sample_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fab37d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess sampled images: resize, gaussian denoise, hair removal, normalize\n",
    "import cv2, numpy as np, os, pandas as pd\n",
    "IMG_SIZE = (224,224)\n",
    "sample_paths = sorted([os.path.join('/content/sample_images', f) for f in os.listdir('/content/sample_images') if f.lower().endswith('.jpg')])\n",
    "print('Number of sampled images:', len(sample_paths))\n",
    "\n",
    "def preprocess(path):\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, IMG_SIZE, interpolation=cv2.INTER_AREA)\n",
    "    img = cv2.GaussianBlur(img, (5,5), sigmaX=1.0)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (9,9))\n",
    "    blackhat = cv2.morphologyEx(gray, cv2.MORPH_BLACKHAT, kernel)\n",
    "    _, thresh = cv2.threshold(blackhat, 10, 255, cv2.THRESH_BINARY)\n",
    "    if thresh.sum() > 0:\n",
    "        img = cv2.inpaint(img, thresh, 1, cv2.INPAINT_TELEA)\n",
    "    img = img.astype('float32')/255.0\n",
    "    return img\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "label_map = {}\n",
    "meta = pd.read_csv('/content/HAM10000/HAM10000_metadata.csv')\n",
    "for p in sample_paths:\n",
    "    imgid = os.path.splitext(os.path.basename(p))[0]\n",
    "    row = meta[meta['image_id'].astype(str)==imgid].iloc[0]\n",
    "    cls = row['dx']\n",
    "    if cls not in label_map:\n",
    "        label_map[cls] = len(label_map)\n",
    "    X.append(preprocess(p))\n",
    "    y.append(label_map[cls])\n",
    "X = np.array(X); y = np.array(y)\n",
    "print('X,y shapes:', X.shape, y.shape)\n",
    "print('Label map:', label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0131dc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split (80:20)\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "print('Train/Test sizes:', train_X.shape[0], test_X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c37bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model (DenseNet201 base + small Dense head)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, applications, optimizers\n",
    "\n",
    "base = applications.DenseNet201(weights='imagenet', include_top=False, input_shape=(224,224,3), pooling='avg')\n",
    "base.trainable = False\n",
    "\n",
    "inp = layers.Input(shape=(224,224,3))\n",
    "x = base(inp, training=False)\n",
    "x = layers.Dense(256, activation='relu')(x)\n",
    "x = layers.Dropout(0.4)(x)\n",
    "out = layers.Dense(len(label_map), activation='softmax')(x)\n",
    "model = models.Model(inp, out)\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253facfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train for a few epochs (demo)\n",
    "history = model.fit(train_X, train_y, validation_split=0.1, epochs=8, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a4ec39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate and report metrics\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_recall_fscore_support\n",
    "preds = np.argmax(model.predict(test_X), axis=1)\n",
    "print('Test accuracy:', accuracy_score(test_y, preds))\n",
    "print('\\nClassification report:')\n",
    "print(classification_report(test_y, preds, target_names=list(label_map.keys()), zero_division=0))\n",
    "cm = confusion_matrix(test_y, preds)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ab9418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance table (Accuracy, Precision, Recall, F1 - macro)\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "perf = {\n",
    "    'Accuracy': accuracy_score(test_y, preds),\n",
    "    'Precision_macro': precision_score(test_y, preds, average='macro', zero_division=0),\n",
    "    'Recall_macro': recall_score(test_y, preds, average='macro', zero_division=0),\n",
    "    'F1_macro': f1_score(test_y, preds, average='macro', zero_division=0)\n",
    "}\n",
    "import pandas as pd\n",
    "pd.DataFrame([perf], index=['DenseNet201_demo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd17e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots: training curves, confusion matrix, and sample predictions\n",
    "import matplotlib.pyplot as plt, seaborn as sns, random\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1); plt.plot(history.history['loss'], label='train_loss'); plt.plot(history.history['val_loss'], label='val_loss'); plt.legend(); plt.title('Loss')\n",
    "plt.subplot(1,2,2); plt.plot(history.history['accuracy'], label='train_acc'); plt.plot(history.history['val_accuracy'], label='val_acc'); plt.legend(); plt.title('Accuracy')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=list(label_map.keys()), yticklabels=list(label_map.keys()))\n",
    "plt.xlabel('Predicted'); plt.ylabel('True'); plt.title('Confusion Matrix'); plt.show()\n",
    "\n",
    "# Show 6 sample predictions from test set\n",
    "plt.figure(figsize=(12,8))\n",
    "idxs = random.sample(range(test_X.shape[0]), min(6, test_X.shape[0]))\n",
    "for i, ix in enumerate(idxs):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.imshow(test_X[ix])\n",
    "    plt.axis('off')\n",
    "    true = list(label_map.keys())[list(label_map.values()).index(test_y[ix])]\n",
    "    pred = list(label_map.keys())[list(label_map.values()).index(preds[ix])]\n",
    "    plt.title(f'True: {true}\\nPred: {pred}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31ec7d6",
   "metadata": {},
   "source": [
    "**End of demo notebook.**\n",
    "\n",
    "Run the notebook step-by-step in Google Colab. Upload `kaggle.json` when prompted so the notebook can download the HAM10000 dataset and run the demo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
